# ğŸ§ª Projet ETL Python â€“ Suivi des commandes revendeurs

## ğŸ“ PrÃ©sentation

Ce projet est un **Proof of Concept (PoC)** acadÃ©mique dÃ©veloppÃ© dans le cadre du module *Extraction, Transformation, Chargement (ETL)* de la formation **DÃ©veloppeur IA** ISEN / Simplon.co.

Il a pour but de concevoir un pipeline **ETL automatisÃ© en Python**, permettant l'intÃ©gration des donnÃ©es de commandes revendeurs (au format CSV) et de stocks/production (via une base SQLite), dans une **base de donnÃ©es MySQL centralisÃ©e**. L'aboutissement du pipeline est la mise Ã  jour de la base stock, avec crÃ©ation de fichiers csv pour le suivi des stocks par produits et par revendeur. Le tout est actuellement **sans interface graphique**, en interaction terminal uniquement.

Le dÃ©veloppement de ce projet a suivi une mÃ©thodologie Agile, avec ticketing et feuille de route sur
[Notion](https://www.notion.so/ba8a83033c684aa798eb9e7c6e2e2ed6).

---
![Python 3.12](https://img.shields.io/badge/Python-3.12%2B-yellow?logo=python&logoColor=yellow)
![Pandas](https://img.shields.io/badge/Pandas-2.3-150458?logo=pandas&logoColor=white)
![pytest](https://img.shields.io/badge/pytest-8.2-0A9EDC?logo=pytest&logoColor=white)
![Ubuntu 24](https://img.shields.io/badge/Ubuntu-24.04-E95420?logo=ubuntu&logoColor=E95420)
![SQLite 3.4](https://img.shields.io/badge/SQLite-3.4-pink?logo=sqlite&logoColor=003B57)
![MySQL](https://img.shields.io/badge/MySQL-8.0+-4479A1?logo=mysql&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-V27-2496ED?logo=docker&logoColor=2496ED)
![VSCode](https://img.shields.io/badge/VSCode-1.10-007ACC?logo=visualstudiocode&logoColor=007ACC)

![tests](https://img.shields.io/badge/coverage-89%-green?logo=pytest&logoColor=white&style=for-the-badge)


## ğŸ§¾ Objectif pÃ©dagogique

- Concevoir une base SQL relationnelle orientÃ©e gestion logistique (revendeurs, produits, rÃ©gions, commandes, stocks),
- DÃ©velopper un pipeline ETL pour :
  - Extraire les donnÃ©es CSV & SQLite,
  - Valider et nettoyer les donnÃ©es (cohÃ©rence, format, doublons...),
  - Charger les donnÃ©es dans une base **MySQL conteneurisÃ©e**,
- GÃ©nÃ©rer un rapport CSV de lâ€™Ã©tat des stocks Ã  date,
- Automatiser le traitement dans une architecture modulaire.

---

## ğŸ§‘â€ğŸ’» Stack technique

| Outil / Techno         | Version / Remarques                        |
|------------------------|--------------------------------------------|
| Python                 | â‰¥ 3.12                                     |
| Pandas                 | 2.3 Manipulation de donnÃ©es structurÃ©es    |
| mysql-connector        | 9.3 BibliothÃ¨que d'interaction avec MySQL  |
| python-dotenv          | chargement des variables d'environnement   |
| pytest (et pytest-cov) | BibliothÃ¨ques de test et couverture        |
| Docker / Docker Compose | Conteneurisation de la base MySQL + Adminer |
| MySQL                  | 8.0+ BDD relationnelle (Port 3307)         |
| Adminer                | Interface web pour MySQL (Port 8081)       |
| SQLite                 | Base lÃ©gÃ¨re Stock source                   |
| CSV                    | Fichier Commandes des revendeur            |
| VSCode                 | IDE de dÃ©veloppement local                 |


---

## âš™ï¸ Installation & mise en route

### 1. PrÃ©-requis

- Python 3.12+
- Docker + Docker Compose installÃ©s
- `pip`, `venv` disponibles en ligne de commande

### 2. Clonage du dÃ©pÃ´t

```bash
git clone https://github.com/TangiLC/isenIA_distributech.git
cd etl
```

Ce projet est rÃ©alisÃ© en trinÃ´me, les contributeurs sont :

*Carole* <a href="https://github.com/Carole-N" target="_blank">
  <img src="https://avatars.githubusercontent.com/Carole-N" width="50" height="50" style="border-radius: 50%;" alt="CaroleN" />
</a>
*Gosia* <a href="https://github.com/go2375" target="_blank">
  <img src="https://avatars.githubusercontent.com/go2375" width="50" height="50" style="border-radius: 50%;" alt="Gosia" />
</a>
*Tangi* <a href="https://github.com/TangiLC" target="_blank">
  <img src="https://avatars.githubusercontent.com/TangiLC" width="50" height="50" style="border-radius: 50%;" alt="TangiLC" />
</a>

### 3. CrÃ©ation du fichier d'environnement et de la base de donnÃ©es

Un fichier contenant les donnÃ©es d'environnement de votre BDD est nÃ©cessaire Ã  la racine du projet.
CrÃ©er et personnalisez le fichier `.env` selon ce schÃ©ma ou copier/renommer le fichier `env.template`:

```bash
BDD_HOST=votre-adresse-host (localhost)
BDD_PORT=votre-port-mysql (3307)
BDD_USER=votre-nom-user-mysql
BDD_PASSWORD=votre-mot-de-passe-mysql
BDD_NAME=votre-nom-de-bdd (distributech)
```

### 4. CrÃ©ation de lâ€™environnement virtuel Python

```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 5. Installation des dÃ©pendances

```bash
pip install -r requirements.txt
```

### 6. Lancement de la base de donnÃ©es

Les fichiers `bdd/script.sql` et `bdd/populate_init.sql` permettent d'initialiser votre base de donnÃ©es.

Alternativement, Dans le dossier `bdd/`, un fichier docker-compose permet de conteneuriser une bdd :

```bash
docker-compose up -d

```

> ğŸ“Œ La base **MySQL** sera alors accessible sur le port `3307`  
> ğŸ–¥ L'interface **Adminer** est disponible via [http://localhost:8081](http://localhost:8081)

 Lancer les scripts d'initialisation depuis l'interface Adminer.

---

## ğŸ§¬ Pipeline ETL

-SchÃ©ma
![SchÃ©ma du pipeline ETL](schema_etl_pipe.png)

### ğŸ“¤ Extract
- Chargement des **commandes revendeurs** depuis un ou plusieurs fichiers `.csv` au format :

```
numero_commande,commande_date,revendeur_id,region_id,product_id,quantity,unit_price
```

- Connexion Ã  une base **SQLite** pour lire :
  - Liste des produits
  - RÃ©partition des revendeurs par rÃ©gion
  - Stock actuel

### ğŸ§¹ Transform
- Validation des donnÃ©es (formats de date, types, cohÃ©rence produit/revendeur)
- Nettoyage des doublons
- Normalisation (majuscule/minuscule, encodage, etc.)

### ğŸ“¥ Load
- Mise Ã  jour de la base MySQL cible via `mysql-connector-python`
- GÃ©nÃ©ration des fichiers `.csv` rÃ©capitulatif de lâ€™Ã©tat des stocks Ã  date
- DÃ©placement des fichiers sources traitÃ©s

---

## âœ“âœ“ Tests unitaires (pytest)

Les bibliothÃ¨ques *pytest* et *pytest-cov* est configurÃ©e avec pytest.ini et .coveragerc.
Les tests sont Ã  lancer Ã  la racine du projet avec la commande suivante :

```
pytest --cov=scripts --cov-report=term --cov-report=html:tests/htmlcov --cov-config=.coveragerc
```

Le coverage sera affichÃ© dans le terminal, avec un objectif >80%.
Le rapport se trouve dans `/tests/htmlcov`. (page principale `index.html`)

---

## ğŸ—ƒ Structure du projet

```
distributech/
â”œâ”€â”€ etl.py                   # Script principal du pipeline (main)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ extracts.py          # Scripts pour les Ã©tapes Extract
â”‚   â”œâ”€â”€ transform_xx.py      # Scripts pour les Ã©tapes Transform
â”‚   â”œâ”€â”€ loads.py             # Scripts pour les Ã©tapes Load
â”‚   â”œâ”€â”€ generate_report.py   # Scripts pour la gÃ©nÃ©ration de l'Ã©tat des Stocks
â”‚   â””â”€utils/                 # Scripts annexes (mise en forme, requÃªtes...)
â”œâ”€â”€ bdd/
â”‚   â”œâ”€â”€ script.sql           # Script de crÃ©ation des tables pour mySQL
â”‚   â”œâ”€â”€ populate_init.sql    # Script d'alimentation initiale de la BDD (produits, rÃ©gions)
â”‚   â””â”€â”€ docker-compose.yml   # Lancement base MySQL + Adminer en container
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ commandes_xxx.csv    # source CSV (Commandes)
â”‚   â”œâ”€â”€ base_stock.sqlite    # Base SQLite (production/rÃ©approvisionnement)
|   â””â”€â”€archived/             # Dossier archive des fichiers antÃ©rieurs
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ schema.sql           # Script de crÃ©ation des tables pour mySQL
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_xxxx.py         # Scripts de tests unitaires pour l'ensemble des fonctions
â”œâ”€â”€ requirements.txt         # DÃ©pendances Python
â”œâ”€â”€ README.md                # Ce fichier ğŸ˜„
â”œâ”€â”€ env.template             # template du .env Ã  personnaliser
â”œâ”€â”€ pytest.ini, .coveragerc  # Fichiers de configuration de l'outil pytest      
â””â”€â”€ .gitignore               # Liste des rÃ©pertoires ou fichiers non suivis
```

---

## ğŸ“¤ DonnÃ©es manipulÃ©es

- **Commandes** : `numero_commande`, `commande_date`, `revendeur_id`, `region_id`, `product_id`, `quantity`, `unit_price`
- **Stocks** : mouvements (entrÃ©es/sorties), calcul des niveaux Ã  date
- **Revendeurs** : `revendeur_id`, `revendeur_name`, `region_id`
- **RÃ©gions** : `region_id`, `region_name`
- **Produits** : `product_id`, `product_name`, `cout_unitaire`

---

## âœ… Livrables attendus

- Scripts Python du pipeline ETL (`etl.py`) et annexes (`/scripts/`)
- Fichier SQL (`script.sql`) pour initialiser la base
- Fichier `.csv` gÃ©nÃ©rÃ© de lâ€™Ã©tat des stocks Ã  date
- Documentation fonctionnelle (ce `README.md`)

---

## ğŸ“œ Licence

Ce projet est sous licence **MIT** â€“ voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ“Œ Ã€ venir

- Factorisation et sÃ©curisation
- Tests de robustesse sur les diffÃ©rentes Ã©tapes ETL
- Affiner les vues BDD selon les exigences mÃ©tier

---

**Bonne lecture !**
